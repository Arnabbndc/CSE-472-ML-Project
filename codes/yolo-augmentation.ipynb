{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6349602c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T22:18:51.880342Z",
     "iopub.status.busy": "2024-12-16T22:18:51.880033Z",
     "iopub.status.idle": "2024-12-16T22:19:05.889845Z",
     "shell.execute_reply": "2024-12-16T22:19:05.889123Z"
    },
    "papermill": {
     "duration": 14.018456,
     "end_time": "2024-12-16T22:19:05.891711",
     "exception": false,
     "start_time": "2024-12-16T22:18:51.873255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99825b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:19:05.904472Z",
     "iopub.status.busy": "2024-12-16T22:19:05.903659Z",
     "iopub.status.idle": "2024-12-16T22:19:15.832589Z",
     "shell.execute_reply": "2024-12-16T22:19:15.831133Z"
    },
    "papermill": {
     "duration": 9.938243,
     "end_time": "2024-12-16T22:19:15.835110",
     "exception": false,
     "start_time": "2024-12-16T22:19:05.896867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wolta\r\n",
      "  Downloading wolta-0.3.5-py3-none-any.whl.metadata (960 bytes)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.2)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from wolta) (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from wolta) (1.26.4)\r\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.10/site-packages (from wolta) (0.2.7)\r\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.7)\r\n",
      "Collecting imblearn (from wolta)\r\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\r\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from wolta) (4.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wolta) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from wolta) (4.10.0.84)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (0.20.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.14.1)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (4.66.4)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.1.0)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (0.10.9.7)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from imblearn->wolta) (0.12.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (3.1.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (3.5.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost->wolta) (8.3.0)\r\n",
      "Downloading wolta-0.3.5-py3-none-any.whl (17 kB)\r\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Installing collected packages: imblearn, wolta\r\n",
      "Successfully installed imblearn-0.0 wolta-0.3.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wolta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3431c3ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:19:15.852144Z",
     "iopub.status.busy": "2024-12-16T22:19:15.851234Z",
     "iopub.status.idle": "2024-12-16T22:19:25.198132Z",
     "shell.execute_reply": "2024-12-16T22:19:25.197079Z"
    },
    "papermill": {
     "duration": 9.357931,
     "end_time": "2024-12-16T22:19:25.200389",
     "exception": false,
     "start_time": "2024-12-16T22:19:15.842458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.50 ultralytics-thop-2.0.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6558e8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:19:25.215082Z",
     "iopub.status.busy": "2024-12-16T22:19:25.214750Z",
     "iopub.status.idle": "2024-12-16T22:19:25.219193Z",
     "shell.execute_reply": "2024-12-16T22:19:25.218543Z"
    },
    "papermill": {
     "duration": 0.013482,
     "end_time": "2024-12-16T22:19:25.220765",
     "exception": false,
     "start_time": "2024-12-16T22:19:25.207283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f700c",
   "metadata": {
    "papermill": {
     "duration": 0.005824,
     "end_time": "2024-12-16T22:19:25.232716",
     "exception": false,
     "start_time": "2024-12-16T22:19:25.226892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209274c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:19:25.245848Z",
     "iopub.status.busy": "2024-12-16T22:19:25.245564Z",
     "iopub.status.idle": "2024-12-16T22:20:14.185890Z",
     "shell.execute_reply": "2024-12-16T22:20:14.184829Z"
    },
    "papermill": {
     "duration": 48.948904,
     "end_time": "2024-12-16T22:20:14.187596",
     "exception": false,
     "start_time": "2024-12-16T22:19:25.238692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\n",
      "/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, _ in os.walk('/kaggle/input/cifake-real-and-ai-generated-synthetic-images'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94de59b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:20:14.201722Z",
     "iopub.status.busy": "2024-12-16T22:20:14.201437Z",
     "iopub.status.idle": "2024-12-16T22:20:14.207657Z",
     "shell.execute_reply": "2024-12-16T22:20:14.206819Z"
    },
    "papermill": {
     "duration": 0.015285,
     "end_time": "2024-12-16T22:20:14.209286",
     "exception": false,
     "start_time": "2024-12-16T22:20:14.194001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE', '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL', '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE', '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL']\n"
     ]
    }
   ],
   "source": [
    "p_paths = glob('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/*')\n",
    "d_paths = []\n",
    "\n",
    "for p_path in p_paths:\n",
    "    d_paths.extend(glob('{}/*'.format(p_path)))\n",
    "print(d_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74b45c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:20:14.224154Z",
     "iopub.status.busy": "2024-12-16T22:20:14.223514Z",
     "iopub.status.idle": "2024-12-16T22:20:14.546029Z",
     "shell.execute_reply": "2024-12-16T22:20:14.545032Z"
    },
    "papermill": {
     "duration": 0.331932,
     "end_time": "2024-12-16T22:20:14.547750",
     "exception": false,
     "start_time": "2024-12-16T22:20:14.215818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    }
   ],
   "source": [
    "i_paths = []\n",
    "\n",
    "for d_path in d_paths:\n",
    "    i_paths.extend(glob('{}/*'.format(d_path)))\n",
    "\n",
    "print(len(i_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e52358b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:20:14.561638Z",
     "iopub.status.busy": "2024-12-16T22:20:14.561374Z",
     "iopub.status.idle": "2024-12-16T22:20:15.132879Z",
     "shell.execute_reply": "2024-12-16T22:20:15.132095Z"
    },
    "papermill": {
     "duration": 0.580362,
     "end_time": "2024-12-16T22:20:15.134669",
     "exception": false,
     "start_time": "2024-12-16T22:20:14.554307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 120000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import get_extensions\n",
    "\n",
    "get_extensions(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce781f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:20:15.149187Z",
     "iopub.status.busy": "2024-12-16T22:20:15.148921Z",
     "iopub.status.idle": "2024-12-16T22:28:05.750132Z",
     "shell.execute_reply": "2024-12-16T22:28:05.749216Z"
    },
    "papermill": {
     "duration": 470.617147,
     "end_time": "2024-12-16T22:28:05.758495",
     "exception": false,
     "start_time": "2024-12-16T22:20:15.141348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import dataset_size_same\n",
    "\n",
    "dataset_size_same(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fbf8f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:28:05.773248Z",
     "iopub.status.busy": "2024-12-16T22:28:05.772957Z",
     "iopub.status.idle": "2024-12-16T22:28:05.780279Z",
     "shell.execute_reply": "2024-12-16T22:28:05.779269Z"
    },
    "papermill": {
     "duration": 0.017866,
     "end_time": "2024-12-16T22:28:05.782914",
     "exception": false,
     "start_time": "2024-12-16T22:28:05.765048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 32\n",
      "Height: 32\n",
      "Ratio: 1.0\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "temp_img = cv2.imread(i_paths[0])\n",
    "ratio = temp_img.shape[1] / temp_img.shape[0]\n",
    "\n",
    "print('Width: {}'.format(temp_img.shape[1]))\n",
    "print('Height: {}'.format(temp_img.shape[0]))\n",
    "print('Ratio: {}'.format(ratio))\n",
    "print(temp_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7f9b0",
   "metadata": {
    "papermill": {
     "duration": 0.009336,
     "end_time": "2024-12-16T22:28:05.803543",
     "exception": false,
     "start_time": "2024-12-16T22:28:05.794207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32e84cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:28:05.826742Z",
     "iopub.status.busy": "2024-12-16T22:28:05.826462Z",
     "iopub.status.idle": "2024-12-16T22:28:05.830925Z",
     "shell.execute_reply": "2024-12-16T22:28:05.830020Z"
    },
    "papermill": {
     "duration": 0.016769,
     "end_time": "2024-12-16T22:28:05.832472",
     "exception": false,
     "start_time": "2024-12-16T22:28:05.815703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891306e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:28:05.853352Z",
     "iopub.status.busy": "2024-12-16T22:28:05.853084Z",
     "iopub.status.idle": "2024-12-16T22:29:58.985313Z",
     "shell.execute_reply": "2024-12-16T22:29:58.984521Z"
    },
    "papermill": {
     "duration": 113.146892,
     "end_time": "2024-12-16T22:29:58.987498",
     "exception": false,
     "start_time": "2024-12-16T22:28:05.840606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d_path in d_paths:\n",
    "    current_dir = Path(d_path).name\n",
    "    current_path = '/kaggle/working/raw/{}'.format(current_dir) \n",
    "    os.makedirs(current_path, exist_ok=True)\n",
    "\n",
    "    i_paths = glob('{}/*'.format(d_path))\n",
    "\n",
    "    for i_path in i_paths:\n",
    "        shutil.copy(i_path, current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a8af0",
   "metadata": {
    "papermill": {
     "duration": 0.006471,
     "end_time": "2024-12-16T22:29:59.001080",
     "exception": false,
     "start_time": "2024-12-16T22:29:58.994609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a456692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:29:59.015189Z",
     "iopub.status.busy": "2024-12-16T22:29:59.014904Z",
     "iopub.status.idle": "2024-12-16T22:30:10.126093Z",
     "shell.execute_reply": "2024-12-16T22:30:10.125362Z"
    },
    "papermill": {
     "duration": 11.120699,
     "end_time": "2024-12-16T22:30:10.128217",
     "exception": false,
     "start_time": "2024-12-16T22:29:59.007518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wolta.visual_tools import dir_split\n",
    "\n",
    "dir_split('/kaggle/working/raw', '/kaggle/working/data', test_size=0.2, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c794538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:30:10.143915Z",
     "iopub.status.busy": "2024-12-16T22:30:10.143602Z",
     "iopub.status.idle": "2024-12-16T22:30:10.147346Z",
     "shell.execute_reply": "2024-12-16T22:30:10.146490Z"
    },
    "papermill": {
     "duration": 0.013386,
     "end_time": "2024-12-16T22:30:10.148956",
     "exception": false,
     "start_time": "2024-12-16T22:30:10.135570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree('/kaggle/working/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc3dfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:30:10.163555Z",
     "iopub.status.busy": "2024-12-16T22:30:10.163289Z",
     "iopub.status.idle": "2024-12-16T22:30:10.166570Z",
     "shell.execute_reply": "2024-12-16T22:30:10.165946Z"
    },
    "papermill": {
     "duration": 0.012297,
     "end_time": "2024-12-16T22:30:10.168203",
     "exception": false,
     "start_time": "2024-12-16T22:30:10.155906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.copytree('/kaggle/input/cifake-data-processed/data', '/kaggle/working/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfb0d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:30:10.182339Z",
     "iopub.status.busy": "2024-12-16T22:30:10.182093Z",
     "iopub.status.idle": "2024-12-16T22:58:58.376046Z",
     "shell.execute_reply": "2024-12-16T22:58:58.374515Z"
    },
    "papermill": {
     "duration": 1728.203403,
     "end_time": "2024-12-16T22:58:58.378028",
     "exception": false,
     "start_time": "2024-12-16T22:30:10.174625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/REAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3694.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/FAKE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:03<00:00, 3596.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/REAL for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:10<00:00, 2808.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/FAKE for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36000/36000 [00:13<00:00, 2715.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/REAL for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2495.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/FAKE for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:04<00:00, 2660.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing global correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [07:12<00:00, 138.63it/s]\n",
      "100%|██████████| 72000/72000 [08:38<00:00, 138.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Matrix.Head()..........\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0 -0.861714 -0.927614 -1.090311 -0.275064  0.072998  0.218769 -0.219931   \n",
      "1  0.764455  0.857541  0.879966  0.824742  0.860862  0.937354  0.911788   \n",
      "2  0.222399  0.181151  0.172908  0.190072  0.156162  0.121783  0.139556   \n",
      "3 -1.285196 -1.265809 -0.995462 -0.779323 -0.859308 -0.953889 -0.952219   \n",
      "4 -1.518111 -1.488419 -1.543001 -1.592223 -0.994995 -0.006064  0.135118   \n",
      "\n",
      "       7         8         9     ...      1014      1015      1016      1017  \\\n",
      "0 -0.475778 -0.524121 -0.847636  ... -1.796203 -1.705298 -1.590924 -1.698824   \n",
      "1  0.803453  0.835759  0.794545  ...  0.120690  0.066883  0.053295  0.046859   \n",
      "2  0.201724  0.352643  0.260611  ... -0.642104 -0.461316 -0.394681 -0.173803   \n",
      "3 -0.988362 -0.966977 -0.914939  ... -0.731262 -0.500807  0.048372 -1.002512   \n",
      "4 -0.538179 -1.186168 -0.865584  ...  0.373304  0.590146  0.668646  0.615677   \n",
      "\n",
      "       1018      1019      1020      1021      1022      1023  \n",
      "0 -1.672028 -1.659591 -1.747806 -1.694756 -1.553472 -1.548893  \n",
      "1  0.037308  0.044862  0.049753  0.059788  0.041169  0.031894  \n",
      "2 -0.353397 -0.639832 -0.621915 -0.649700 -0.777572 -0.739680  \n",
      "3 -0.919920 -0.804936 -0.974662 -0.194285  0.602864  0.615280  \n",
      "4  0.589179  0.583877  0.576457  0.543965  0.483861  0.422386  \n",
      "\n",
      "[5 rows x 1024 columns]\n",
      "Correlation.Head()...........\n",
      "0    0.206783\n",
      "1    0.199780\n",
      "2    0.195665\n",
      "3    0.189811\n",
      "4    0.184389\n",
      "dtype: float64\n",
      "Max correlation: 0.20678259052856002\n",
      "Min correlation: 0.0016969001028711514\n",
      "Max correlation index: 0\n",
      "Size of correlation: 1024\n",
      "Processing train/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [03:15<00:00, 306.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72000/72000 [03:53<00:00, 307.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:05<00:00, 305.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [01:18<00:00, 306.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:05<00:00, 305.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [01:18<00:00, 305.85it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    \"\"\"Randomly resize the image and then resize it back to the original size.\"\"\"\n",
    "    resize_factor = random.uniform(0.8, 1.2)  # Resize between 80% to 120%\n",
    "    new_size = (int(image.shape[1] * resize_factor), int(image.shape[0] * resize_factor))\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.resize(new_size, Image.Resampling.LANCZOS)  # Resize\n",
    "    pil_img = pil_img.resize(target_size, Image.Resampling.LANCZOS)  # Resize back to original size\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def rotate_image(image, target_size):\n",
    "    \"\"\"Randomly rotate the image and crop it to the original size.\"\"\"\n",
    "    angle = random.uniform(-90, 90)  # Rotate between -30 to 30 degrees\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n",
    "\n",
    "    # Center crop back to the original size\n",
    "    pil_img = ImageOps.fit(pil_img, target_size, Image.Resampling.LANCZOS)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def adjust_sharpness(image):\n",
    "    \"\"\"Randomly adjust sharpness of the image.\"\"\"\n",
    "    sharpness_factor = random.uniform(0.5, 2.0)  # Sharpness between 0.5x to 2x\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Sharpness(pil_img)\n",
    "    pil_img = enhancer.enhance(sharpness_factor)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def zoom_image(image, target_size):\n",
    "    \"\"\"Randomly zoom the image and resize it back to the original size.\"\"\"\n",
    "    zoom_factor = random.uniform(0.8, 1.2)  # Zoom between 80% to 120%\n",
    "    zoom_size = (int(image.shape[1] * zoom_factor), int(image.shape[0] * zoom_factor))\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.resize(zoom_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Center crop back to the original size\n",
    "    pil_img = ImageOps.fit(pil_img, target_size, Image.Resampling.LANCZOS)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def horizontal_flip_image(image):\n",
    "    \"\"\"Randomly flip the image horizontally.\"\"\"\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = ImageOps.mirror(pil_img)  # Flip horizontally\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def augment_image_randomly(image):\n",
    "    \"\"\"\n",
    "    Randomly select and apply one augmentation technique to the image.\n",
    "    \"\"\"\n",
    "    target_size = (image.shape[1], image.shape[0])  # Original width and height\n",
    "    augmentations = [\n",
    "        lambda img: resize_image(img, target_size),\n",
    "        lambda img: rotate_image(img, target_size),\n",
    "        adjust_sharpness,\n",
    "        lambda img: zoom_image(img, target_size),\n",
    "        horizontal_flip_image\n",
    "    ]\n",
    "    augmentation = random.choice(augmentations)\n",
    "    return augmentation(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_dropped_patches = 0\n",
    "def add_gaussian_noise(image, mean=0, std=1):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def reduce_resolution(image, target_size=(16, 16)):\n",
    "    \"\"\"Reduce and then restore the resolution of an image.\"\"\"\n",
    "    low_res = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    restored = cv2.resize(low_res, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    return restored\n",
    "\n",
    "def extract_patches(image, patch_size=1):\n",
    "    \"\"\"\n",
    "    Extract patches from an image.\n",
    "    Returns a list of flattened patch intensities.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    patches = []\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size].flatten()\n",
    "            patches.append(np.mean(patch))  # Use mean intensity as a feature\n",
    "    return patches\n",
    "\n",
    "def compute_global_correlation(data_dir, categories, patch_size=1):\n",
    "    \"\"\"\n",
    "    Compute the correlation of patches across the entire dataset with the label.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for img_name in tqdm(os.listdir(category_path)):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    # print(\"image shape\", image.shape)\n",
    "                    features = extract_patches(image, patch_size)\n",
    "                    # print(\"total patches:\", len(features))\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "    # print(len(all_features))\n",
    "    all_features = StandardScaler().fit_transform(all_features)\n",
    "    # Convert to a DataFrame for correlation calculation\n",
    "    feature_matrix = pd.DataFrame(all_features)  # Rows = images, Columns = patches\n",
    "    print(\"Feature_Matrix.Head()..........\")\n",
    "    print(feature_matrix.head())\n",
    "    label_series = pd.Series(all_labels, name=\"label\")\n",
    "    # print(label_series)\n",
    "    correlations = feature_matrix.corrwith(label_series)  # Correlation of each patch with the label\n",
    "    print(\"Correlation.Head()...........\")\n",
    "    print(correlations.head())\n",
    "    print(f\"Max correlation: {abs(correlations.max())}\")\n",
    "    print(f\"Min correlation: {abs(correlations.min())}\")\n",
    "    print(f\"Max correlation index: {abs(correlations).idxmax()}\")\n",
    "    print(f\"Size of correlation: {correlations.size}\")\n",
    "\n",
    "    return correlations\n",
    "\n",
    "def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Drop patches with the least correlation to the label.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    dropped_image = image.copy()\n",
    "    patch_idx = 0\n",
    "\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "                dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "                # n_dropped_patches += 1\n",
    "            patch_idx += 1\n",
    "\n",
    "    return dropped_image\n",
    "\n",
    "def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Process the entire dataset by dropping least correlated patches and saving.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    for img_name in tqdm(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                processed_image = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "                output_img_path = os.path.join(output_dir, img_name)\n",
    "                cv2.imwrite(output_img_path, processed_image)\n",
    "                    \n",
    "\n",
    "\n",
    "# def normalize_image(image):\n",
    "#     \"\"\"Normalize image to range [0, 1].\"\"\"\n",
    "#     return image / 255.0\n",
    "    \n",
    "def process_and_save_images(input_path, output_path, preprocess_fn, augment = True):\n",
    "    \"\"\"Process images with a given preprocessing function and save.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    image_paths = os.listdir(input_path)\n",
    "    for img_name in tqdm(image_paths):\n",
    "        img_path = os.path.join(input_path, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            processed_image = preprocess_fn(image)\n",
    "            if augment:\n",
    "                img_name = img_name.split('.')[0] + '_1.' + img_name.split('.')[1]\n",
    "            output_img_path = os.path.join(output_path, img_name)\n",
    "            cv2.imwrite(output_img_path, (processed_image * 255).astype(np.uint8) if processed_image.max() <= 1 else processed_image)\n",
    "\n",
    "\n",
    "base_dir = \"/kaggle/working/data\"  # Replace with the root path of your dataset\n",
    "subsets = [ \"train\",\"val\"]\n",
    "categories = {\"REAL\": 1, \"FAKE\": 0}\n",
    "train_data_dir = \"/kaggle/working/data/train\"  # Training data directory\n",
    "\n",
    "test_real_path = \"/kaggle/working/data/test/REAL\"\n",
    "test_fake_path = \"/kaggle/working/data/test/FAKE\"\n",
    "\n",
    "print(f\"Processing test/REAL...\")\n",
    "process_and_save_images(test_real_path, test_real_path, lambda img: add_gaussian_noise(img))\n",
    "print(f\"Processing test/FAKE...\")\n",
    "process_and_save_images(test_fake_path, test_fake_path, lambda img: add_gaussian_noise(img))\n",
    "\n",
    "# Apply the Robustness Methods to train and val set\n",
    "for subset in subsets:\n",
    "    for category, label in categories.items():\n",
    "        input_path = os.path.join(base_dir, subset, category)\n",
    "        # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "        print(f\"Processing {subset}/{category} for random augmentation...\")\n",
    "        process_and_save_images(input_path, input_path, lambda img: augment_image_randomly(img))\n",
    "\n",
    "\n",
    "print(\"Computing global correlation...\")\n",
    "correlations = compute_global_correlation(train_data_dir, categories, patch_size=1)\n",
    "\n",
    "all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# drop least correlated features from all sets \n",
    "for subset in all_subsets:\n",
    "    for category, label in categories.items():\n",
    "        # n_dropped_patches = 0\n",
    "        input_path = os.path.join(base_dir, subset, category)        \n",
    "        print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "        process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.01)\n",
    "\n",
    "# Apply the Robustness Methods to train and val set\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         # print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         # process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))\n",
    "        \n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for normalization...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: normalize_image(img), augment = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd9f099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:58:59.893991Z",
     "iopub.status.busy": "2024-12-16T22:58:59.892968Z",
     "iopub.status.idle": "2024-12-16T22:58:59.897730Z",
     "shell.execute_reply": "2024-12-16T22:58:59.896954Z"
    },
    "papermill": {
     "duration": 0.764268,
     "end_time": "2024-12-16T22:58:59.899442",
     "exception": false,
     "start_time": "2024-12-16T22:58:59.135174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree('/kaggle/working/kaggle')\n",
    "# shutil.copytree('/kaggle/input/cifake-data-processed/data', '/kaggle/working/data_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119eb9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:01.368915Z",
     "iopub.status.busy": "2024-12-16T22:59:01.368551Z",
     "iopub.status.idle": "2024-12-16T22:59:01.372934Z",
     "shell.execute_reply": "2024-12-16T22:59:01.371860Z"
    },
    "papermill": {
     "duration": 0.762112,
     "end_time": "2024-12-16T22:59:01.374508",
     "exception": false,
     "start_time": "2024-12-16T22:59:00.612396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original_data_dir = \"/kaggle/working/data_original\"\n",
    "# data_dir = \"/kaggle/working/data\"\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(original_data_dir, subset, category)\n",
    "#         output_path = os.path.join(data_dir, subset, category)\n",
    "#         if not os.path.exists(output_path):\n",
    "#             os.makedirs(output_path)\n",
    "#         image_paths = os.listdir(input_path)\n",
    "#         if len(image_paths) > 0.1 * len(image_paths):\n",
    "#             image_paths = image_paths[int(0.1 * len(image_paths)):]\n",
    "#             for img_name in image_paths:\n",
    "#                 img_path = os.path.join(input_path, img_name)\n",
    "#                 shutil.copy(img_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5055690f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:02.904158Z",
     "iopub.status.busy": "2024-12-16T22:59:02.903834Z",
     "iopub.status.idle": "2024-12-16T22:59:02.908424Z",
     "shell.execute_reply": "2024-12-16T22:59:02.907364Z"
    },
    "papermill": {
     "duration": 0.776231,
     "end_time": "2024-12-16T22:59:02.910265",
     "exception": false,
     "start_time": "2024-12-16T22:59:02.134034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Drop 80% of the images in the training set\n",
    "# all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         image_paths = os.listdir(input_path)\n",
    "#         if len(image_paths) > 0.2 * len(image_paths):\n",
    "#             image_paths = image_paths[:int(0.8 * len(image_paths))]\n",
    "#             for img_name in image_paths:\n",
    "#                 img_path = os.path.join(input_path, img_name)\n",
    "#                 os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e94a25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:04.401942Z",
     "iopub.status.busy": "2024-12-16T22:59:04.401211Z",
     "iopub.status.idle": "2024-12-16T22:59:04.405662Z",
     "shell.execute_reply": "2024-12-16T22:59:04.404607Z"
    },
    "papermill": {
     "duration": 0.787623,
     "end_time": "2024-12-16T22:59:04.407891",
     "exception": false,
     "start_time": "2024-12-16T22:59:03.620268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Apply the Robustness Methods to train and val set\n",
    "# for subset in subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for random augmentation...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: augment_image_randomly(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c6d0dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:06.021499Z",
     "iopub.status.busy": "2024-12-16T22:59:06.020923Z",
     "iopub.status.idle": "2024-12-16T22:59:06.025842Z",
     "shell.execute_reply": "2024-12-16T22:59:06.025079Z"
    },
    "papermill": {
     "duration": 0.765635,
     "end_time": "2024-12-16T22:59:06.027482",
     "exception": false,
     "start_time": "2024-12-16T22:59:05.261847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_dropped_patches = 0\n",
    "# def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Drop patches with the least correlation to the label.\n",
    "#     \"\"\"\n",
    "#     height, width, _ = image.shape\n",
    "#     dropped_image = image.copy()\n",
    "#     patch_idx = 0\n",
    "#     n_dropped_patches = 0\n",
    "#     for i in range(0, height, patch_size):\n",
    "#         for j in range(0, width, patch_size):\n",
    "#             if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "#                 dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "#                 n_dropped_patches += 1\n",
    "#             patch_idx += 1\n",
    "#     print(f\"Dropped {n_dropped_patches} patches in this image\")\n",
    "#     return dropped_image, n_dropped_patches\n",
    "# def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Process the entire dataset by dropping least correlated patches and saving.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     n_dropped_patches = 0\n",
    "#     for img_name in tqdm(os.listdir(data_dir)):\n",
    "#         img_path = os.path.join(data_dir, img_name)\n",
    "#         if os.path.isfile(img_path):\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 processed_image, n_d = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "#                 n_dropped_patches += n_d\n",
    "#                 output_img_path = os.path.join(output_dir, img_name)\n",
    "#                 cv2.imwrite(output_img_path, processed_image)\n",
    "#     return n_dropped_patches \n",
    "                \n",
    "# all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# # drop least correlated features from all sets \n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         n_dropped_patches = 0\n",
    "#         input_path = os.path.join(base_dir, subset, category)   \n",
    "#         output_path = os.path.join(base_dir, subset, category+\"_processed\")\n",
    "#         print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "#         n_dropped_patches = process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.02)\n",
    "#         print(f\"Dropped {n_dropped_patches} patches in total in images of {subset}/{category}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1742714a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:07.498771Z",
     "iopub.status.busy": "2024-12-16T22:59:07.497834Z",
     "iopub.status.idle": "2024-12-16T22:59:07.501951Z",
     "shell.execute_reply": "2024-12-16T22:59:07.501021Z"
    },
    "papermill": {
     "duration": 0.72139,
     "end_time": "2024-12-16T22:59:07.503895",
     "exception": false,
     "start_time": "2024-12-16T22:59:06.782505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r '/kaggle/working/data/train.cache'\n",
    "# !rm -r '/kaggle/working/data/val.cache'\n",
    "# !rm -r '/kaggle/working/data/test.cache'\n",
    "# !rm -r '/kaggle/working/runs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415eb75f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:09.013424Z",
     "iopub.status.busy": "2024-12-16T22:59:09.012790Z",
     "iopub.status.idle": "2024-12-16T22:59:09.016496Z",
     "shell.execute_reply": "2024-12-16T22:59:09.015725Z"
    },
    "papermill": {
     "duration": 0.76124,
     "end_time": "2024-12-16T22:59:09.018186",
     "exception": false,
     "start_time": "2024-12-16T22:59:08.256946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for subset in subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d3b07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:10.490421Z",
     "iopub.status.busy": "2024-12-16T22:59:10.490095Z",
     "iopub.status.idle": "2024-12-16T22:59:10.923475Z",
     "shell.execute_reply": "2024-12-16T22:59:10.922551Z"
    },
    "papermill": {
     "duration": 1.15519,
     "end_time": "2024-12-16T22:59:10.925282",
     "exception": false,
     "start_time": "2024-12-16T22:59:09.770092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REAL': 100000, 'FAKE': 120000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import cls_img_counter\n",
    "\n",
    "cls_img_counter('/kaggle/working/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfeef59",
   "metadata": {
    "papermill": {
     "duration": 0.762784,
     "end_time": "2024-12-16T22:59:12.440384",
     "exception": false,
     "start_time": "2024-12-16T22:59:11.677600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5913ec77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:59:13.926665Z",
     "iopub.status.busy": "2024-12-16T22:59:13.925724Z",
     "iopub.status.idle": "2024-12-16T23:48:54.251446Z",
     "shell.execute_reply": "2024-12-16T23:48:54.250585Z"
    },
    "papermill": {
     "duration": 2981.045709,
     "end_time": "2024-12-16T23:48:54.253933",
     "exception": false,
     "start_time": "2024-12-16T22:59:13.208224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt to 'yolo11x-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56.9M/56.9M [00:00<00:00, 192MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/kaggle/working/data, epochs=5, time=None, patience=100, batch=16, imgsz=32, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLO11x-cls summary: 309 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 74.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/train... 132000 images, 0 corrupt: 100%|██████████| 132000/132000 [01:02<00:00, 2107.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/val... 44000 images, 0 corrupt: 100%|██████████| 44000/44000 [00:20<00:00, 2129.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 32 train, 32 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.682G     0.9899         16         32:   0%|          | 4/8250 [00:01<27:46,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.682G     0.9423         16         32:   0%|          | 10/8250 [00:01<13:24, 10.25it/s]\n",
      "100%|██████████| 755k/755k [00:00<00:00, 16.5MB/s]\n",
      "        1/5     0.694G     0.5672         16         32: 100%|██████████| 8250/8250 [10:04<00:00, 13.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:28<00:00, 48.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5     0.694G     0.5501         16         32: 100%|██████████| 8250/8250 [09:03<00:00, 15.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:28<00:00, 48.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.866          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5     0.705G     0.5363         16         32: 100%|██████████| 8250/8250 [08:40<00:00, 15.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:27<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.869          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5     0.711G     0.3917         16         32: 100%|██████████| 8250/8250 [08:37<00:00, 15.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:28<00:00, 48.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       0.7G      0.329         16         32: 100%|██████████| 8250/8250 [08:32<00:00, 16.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:28<00:00, 48.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.911          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.792 hours.\n",
      "Optimizer stripped from runs/classify/train/weights/last.pt, 57.0MB\n",
      "Optimizer stripped from runs/classify/train/weights/best.pt, 57.0MB\n",
      "\n",
      "Validating runs/classify/train/weights/best.pt...\n",
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:21<00:00, 64.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.911          1\n",
      "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model='yolo11x-cls.pt')\n",
    "results = model.train(data='/kaggle/working/data', epochs=5, imgsz=32, verbose= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8e3fb16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T23:49:02.037631Z",
     "iopub.status.busy": "2024-12-16T23:49:02.037292Z",
     "iopub.status.idle": "2024-12-16T23:50:01.141656Z",
     "shell.execute_reply": "2024-12-16T23:50:01.140847Z"
    },
    "papermill": {
     "duration": 62.969045,
     "end_time": "2024-12-16T23:50:01.143974",
     "exception": false,
     "start_time": "2024-12-16T23:48:58.174929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/test... 44000 images, 0 corrupt: 100%|██████████| 44000/44000 [00:20<00:00, 2146.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /kaggle/working/data/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 2750/2750 [00:33<00:00, 81.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.736          1\n",
      "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "test_results = model.val(data='/kaggle/working/data', imgsz=32, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d78e3574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T23:50:09.206650Z",
     "iopub.status.busy": "2024-12-16T23:50:09.206330Z",
     "iopub.status.idle": "2024-12-16T23:50:14.480654Z",
     "shell.execute_reply": "2024-12-16T23:50:14.479666Z"
    },
    "papermill": {
     "duration": 9.446454,
     "end_time": "2024-12-16T23:50:14.485924",
     "exception": false,
     "start_time": "2024-12-16T23:50:05.039470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "model.save('trained_yolo_model.pt')\n",
    "shutil.rmtree('/kaggle/working/data')\n",
    "# shutil.rmtree('/kaggle/working/raw')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3041726,
     "sourceId": 5256696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5492.090625,
   "end_time": "2024-12-16T23:50:21.339705",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T22:18:49.249080",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
