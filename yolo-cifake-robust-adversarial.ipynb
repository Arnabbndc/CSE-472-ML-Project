{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037ce1e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T20:23:52.750167Z",
     "iopub.status.busy": "2024-12-16T20:23:52.749885Z",
     "iopub.status.idle": "2024-12-16T20:24:04.349981Z",
     "shell.execute_reply": "2024-12-16T20:24:04.349244Z"
    },
    "papermill": {
     "duration": 11.608392,
     "end_time": "2024-12-16T20:24:04.351980",
     "exception": false,
     "start_time": "2024-12-16T20:23:52.743588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e1108b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:04.364296Z",
     "iopub.status.busy": "2024-12-16T20:24:04.363854Z",
     "iopub.status.idle": "2024-12-16T20:24:13.908917Z",
     "shell.execute_reply": "2024-12-16T20:24:13.907941Z"
    },
    "papermill": {
     "duration": 9.554058,
     "end_time": "2024-12-16T20:24:13.911210",
     "exception": false,
     "start_time": "2024-12-16T20:24:04.357152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wolta\r\n",
      "  Downloading wolta-0.3.5-py3-none-any.whl.metadata (960 bytes)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.2)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from wolta) (2.2.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from wolta) (1.26.4)\r\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.10/site-packages (from wolta) (0.2.7)\r\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.7)\r\n",
      "Collecting imblearn (from wolta)\r\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\r\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from wolta) (4.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wolta) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from wolta) (4.10.0.84)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (0.20.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.14.1)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (4.66.4)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.0.0)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (0.10.9.7)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from imblearn->wolta) (0.12.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (3.1.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (3.5.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost->wolta) (8.3.0)\r\n",
      "Downloading wolta-0.3.5-py3-none-any.whl (17 kB)\r\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Installing collected packages: imblearn, wolta\r\n",
      "Successfully installed imblearn-0.0 wolta-0.3.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wolta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e45e7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:13.924034Z",
     "iopub.status.busy": "2024-12-16T20:24:13.923704Z",
     "iopub.status.idle": "2024-12-16T20:24:23.116506Z",
     "shell.execute_reply": "2024-12-16T20:24:23.115582Z"
    },
    "papermill": {
     "duration": 9.201644,
     "end_time": "2024-12-16T20:24:23.118688",
     "exception": false,
     "start_time": "2024-12-16T20:24:13.917044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.50 ultralytics-thop-2.0.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42671574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.133327Z",
     "iopub.status.busy": "2024-12-16T20:24:23.132718Z",
     "iopub.status.idle": "2024-12-16T20:24:23.137152Z",
     "shell.execute_reply": "2024-12-16T20:24:23.136457Z"
    },
    "papermill": {
     "duration": 0.013484,
     "end_time": "2024-12-16T20:24:23.138777",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.125293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f39a41",
   "metadata": {
    "papermill": {
     "duration": 0.006038,
     "end_time": "2024-12-16T20:24:23.151042",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.145004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cb3b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.164103Z",
     "iopub.status.busy": "2024-12-16T20:24:23.163844Z",
     "iopub.status.idle": "2024-12-16T20:24:23.167046Z",
     "shell.execute_reply": "2024-12-16T20:24:23.166312Z"
    },
    "papermill": {
     "duration": 0.011627,
     "end_time": "2024-12-16T20:24:23.168674",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.157047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dirname, _, _ in os.walk('/kaggle/input'):\n",
    "#     print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e77197f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.181886Z",
     "iopub.status.busy": "2024-12-16T20:24:23.181668Z",
     "iopub.status.idle": "2024-12-16T20:24:23.184953Z",
     "shell.execute_reply": "2024-12-16T20:24:23.184188Z"
    },
    "papermill": {
     "duration": 0.011828,
     "end_time": "2024-12-16T20:24:23.186536",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.174708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p_paths = glob('/kaggle/input/*')\n",
    "# d_paths = []\n",
    "\n",
    "# for p_path in p_paths:\n",
    "#     d_paths.extend(glob('{}/*'.format(p_path)))\n",
    "# print(d_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97680376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.199686Z",
     "iopub.status.busy": "2024-12-16T20:24:23.199428Z",
     "iopub.status.idle": "2024-12-16T20:24:23.202721Z",
     "shell.execute_reply": "2024-12-16T20:24:23.201970Z"
    },
    "papermill": {
     "duration": 0.011559,
     "end_time": "2024-12-16T20:24:23.204237",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.192678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i_paths = []\n",
    "\n",
    "# for d_path in d_paths:\n",
    "#     i_paths.extend(glob('{}/*'.format(d_path)))\n",
    "\n",
    "# print(len(i_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b99e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.217257Z",
     "iopub.status.busy": "2024-12-16T20:24:23.217002Z",
     "iopub.status.idle": "2024-12-16T20:24:23.220242Z",
     "shell.execute_reply": "2024-12-16T20:24:23.219483Z"
    },
    "papermill": {
     "duration": 0.011531,
     "end_time": "2024-12-16T20:24:23.221744",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.210213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from wolta.visual_tools import get_extensions\n",
    "\n",
    "# get_extensions(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96882eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.234664Z",
     "iopub.status.busy": "2024-12-16T20:24:23.234416Z",
     "iopub.status.idle": "2024-12-16T20:24:23.237525Z",
     "shell.execute_reply": "2024-12-16T20:24:23.236879Z"
    },
    "papermill": {
     "duration": 0.011326,
     "end_time": "2024-12-16T20:24:23.239004",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.227678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from wolta.visual_tools import dataset_size_same\n",
    "\n",
    "# dataset_size_same(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a49107e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.252145Z",
     "iopub.status.busy": "2024-12-16T20:24:23.251705Z",
     "iopub.status.idle": "2024-12-16T20:24:23.254845Z",
     "shell.execute_reply": "2024-12-16T20:24:23.254132Z"
    },
    "papermill": {
     "duration": 0.011386,
     "end_time": "2024-12-16T20:24:23.256379",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.244993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temp_img = cv2.imread(i_paths[0])\n",
    "# ratio = temp_img.shape[1] / temp_img.shape[0]\n",
    "\n",
    "# print('Width: {}'.format(temp_img.shape[1]))\n",
    "# print('Height: {}'.format(temp_img.shape[0]))\n",
    "# print('Ratio: {}'.format(ratio))\n",
    "# print(temp_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a5ae6",
   "metadata": {
    "papermill": {
     "duration": 0.005878,
     "end_time": "2024-12-16T20:24:23.268585",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.262707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254731c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.281496Z",
     "iopub.status.busy": "2024-12-16T20:24:23.281270Z",
     "iopub.status.idle": "2024-12-16T20:24:23.284431Z",
     "shell.execute_reply": "2024-12-16T20:24:23.283787Z"
    },
    "papermill": {
     "duration": 0.011318,
     "end_time": "2024-12-16T20:24:23.285879",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.274561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.makedirs('/kaggle/working/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fdf4a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.298833Z",
     "iopub.status.busy": "2024-12-16T20:24:23.298613Z",
     "iopub.status.idle": "2024-12-16T20:24:23.301856Z",
     "shell.execute_reply": "2024-12-16T20:24:23.301230Z"
    },
    "papermill": {
     "duration": 0.01143,
     "end_time": "2024-12-16T20:24:23.303383",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.291953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for d_path in d_paths:\n",
    "#     current_dir = Path(d_path).name\n",
    "#     current_path = '/kaggle/working/raw/{}'.format(current_dir) \n",
    "#     os.makedirs(current_path, exist_ok=True)\n",
    "\n",
    "#     i_paths = glob('{}/*'.format(d_path))\n",
    "\n",
    "#     for i_path in i_paths:\n",
    "#         shutil.copy(i_path, current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b55340",
   "metadata": {
    "papermill": {
     "duration": 0.005758,
     "end_time": "2024-12-16T20:24:23.315184",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.309426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "490e9228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.328139Z",
     "iopub.status.busy": "2024-12-16T20:24:23.327864Z",
     "iopub.status.idle": "2024-12-16T20:24:23.330939Z",
     "shell.execute_reply": "2024-12-16T20:24:23.330195Z"
    },
    "papermill": {
     "duration": 0.011329,
     "end_time": "2024-12-16T20:24:23.332432",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.321103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from wolta.visual_tools import dir_split\n",
    "\n",
    "# dir_split('/kaggle/working/raw', '/kaggle/working/data', test_size=0.2, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29535091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.345728Z",
     "iopub.status.busy": "2024-12-16T20:24:23.345488Z",
     "iopub.status.idle": "2024-12-16T20:24:23.348643Z",
     "shell.execute_reply": "2024-12-16T20:24:23.347964Z"
    },
    "papermill": {
     "duration": 0.011614,
     "end_time": "2024-12-16T20:24:23.350216",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.338602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree('/kaggle/working/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d264567f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:24:23.363140Z",
     "iopub.status.busy": "2024-12-16T20:24:23.362868Z",
     "iopub.status.idle": "2024-12-16T20:34:27.357347Z",
     "shell.execute_reply": "2024-12-16T20:34:27.356238Z"
    },
    "papermill": {
     "duration": 604.0083,
     "end_time": "2024-12-16T20:34:27.364528",
     "exception": false,
     "start_time": "2024-12-16T20:24:23.356228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree('/kaggle/input/cifake-data-processed/data', '/kaggle/working/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d3dc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T20:34:27.378416Z",
     "iopub.status.busy": "2024-12-16T20:34:27.378142Z",
     "iopub.status.idle": "2024-12-16T21:02:18.463032Z",
     "shell.execute_reply": "2024-12-16T21:02:18.461957Z"
    },
    "papermill": {
     "duration": 1671.093996,
     "end_time": "2024-12-16T21:02:18.464614",
     "exception": false,
     "start_time": "2024-12-16T20:34:27.370618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/REAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3922.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/FAKE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:03<00:00, 3923.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/REAL for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:09<00:00, 3179.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/FAKE for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36000/36000 [00:11<00:00, 3202.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/REAL for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3233.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/FAKE for random augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:03<00:00, 3196.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing global correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [07:13<00:00, 138.52it/s]\n",
      "100%|██████████| 72000/72000 [08:39<00:00, 138.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Matrix.Head()..........\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0 -1.476841 -1.373998 -1.319367 -1.354325 -1.407898 -1.438976 -1.489199   \n",
      "1 -1.605651 -1.571353 -1.491092 -1.527570 -1.687565 -1.775792 -1.549504   \n",
      "2  0.686270  1.030151  0.718739  0.451071  0.728575  0.438888  0.421987   \n",
      "3 -1.396890 -1.445764 -1.391672 -1.267702 -1.247433 -1.268261 -1.118095   \n",
      "4 -0.348648 -0.355823 -0.560161 -0.752526 -0.715607 -0.714591 -0.784102   \n",
      "\n",
      "       7         8         9     ...      1014      1015      1016      1017  \\\n",
      "0 -1.542654 -1.613281 -1.477931  ... -1.201042 -1.132386 -1.151517 -1.169563   \n",
      "1 -1.128637 -0.548146 -0.325915  ...  0.193443 -0.034795 -0.632610 -0.532243   \n",
      "2  0.587906  1.250436  1.210107  ...  0.130296  0.185774  1.049907  0.961803   \n",
      "3 -0.896043 -1.024654 -1.103292  ...  0.103985 -0.197595 -0.800338 -0.850903   \n",
      "4 -0.756487 -0.856475 -0.887874  ...  1.019609  1.325379  1.453501  1.505092   \n",
      "\n",
      "       1018      1019      1020      1021      1022      1023  \n",
      "0 -1.211663 -1.356082 -1.556659 -1.706633 -1.666129 -1.548353  \n",
      "1 -0.665710 -1.045768 -1.165776 -0.890800 -0.522258 -0.356685  \n",
      "2  0.446995  0.485115  1.205238  0.465523  0.161028  1.075318  \n",
      "3 -1.180465 -1.133690 -0.877757 -0.707237 -0.633608 -0.957526  \n",
      "4  1.460908  1.462604  1.508686  1.342544  1.279592  1.415795  \n",
      "\n",
      "[5 rows x 1024 columns]\n",
      "Correlation.Head()...........\n",
      "0    0.220750\n",
      "1    0.215529\n",
      "2    0.210546\n",
      "3    0.203582\n",
      "4    0.198906\n",
      "dtype: float64\n",
      "Max correlation: 0.2207496308498084\n",
      "Min correlation: 0.002541285579735633\n",
      "Max correlation index: 0\n",
      "Size of correlation: 1024\n",
      "Processing train/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [03:00<00:00, 331.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72000/72000 [03:38<00:00, 330.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:00<00:00, 331.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [01:12<00:00, 330.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:00<00:00, 331.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [01:12<00:00, 331.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    \"\"\"Randomly resize the image and then resize it back to the original size.\"\"\"\n",
    "    resize_factor = random.uniform(0.8, 1.2)  # Resize between 80% to 120%\n",
    "    new_size = (int(image.shape[1] * resize_factor), int(image.shape[0] * resize_factor))\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.resize(new_size, Image.Resampling.LANCZOS)  # Resize\n",
    "    pil_img = pil_img.resize(target_size, Image.Resampling.LANCZOS)  # Resize back to original size\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def rotate_image(image, target_size):\n",
    "    \"\"\"Randomly rotate the image and crop it to the original size.\"\"\"\n",
    "    angle = random.uniform(-30, 30)  # Rotate between -30 to 30 degrees\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n",
    "\n",
    "    # Center crop back to the original size\n",
    "    pil_img = ImageOps.fit(pil_img, target_size, Image.Resampling.LANCZOS)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def adjust_sharpness(image):\n",
    "    \"\"\"Randomly adjust sharpness of the image.\"\"\"\n",
    "    sharpness_factor = random.uniform(0.5, 2.0)  # Sharpness between 0.5x to 2x\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Sharpness(pil_img)\n",
    "    pil_img = enhancer.enhance(sharpness_factor)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def zoom_image(image, target_size):\n",
    "    \"\"\"Randomly zoom the image and resize it back to the original size.\"\"\"\n",
    "    zoom_factor = random.uniform(0.8, 1.2)  # Zoom between 80% to 120%\n",
    "    zoom_size = (int(image.shape[1] * zoom_factor), int(image.shape[0] * zoom_factor))\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = pil_img.resize(zoom_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Center crop back to the original size\n",
    "    pil_img = ImageOps.fit(pil_img, target_size, Image.Resampling.LANCZOS)\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def horizontal_flip_image(image):\n",
    "    \"\"\"Randomly flip the image horizontally.\"\"\"\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    pil_img = ImageOps.mirror(pil_img)  # Flip horizontally\n",
    "    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=1):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "    \n",
    "def augment_image_randomly(image):\n",
    "    \"\"\"\n",
    "    Randomly select and apply one augmentation technique to the image.\n",
    "    \"\"\"\n",
    "    target_size = (image.shape[1], image.shape[0])  # Original width and height\n",
    "    augmentations = [\n",
    "        add_gaussian_noise,\n",
    "        lambda img: resize_image(img, target_size),\n",
    "        add_gaussian_noise,\n",
    "        lambda img: rotate_image(img, target_size),\n",
    "        adjust_sharpness,\n",
    "        add_gaussian_noise,\n",
    "        lambda img: zoom_image(img, target_size),\n",
    "        horizontal_flip_image,\n",
    "        add_gaussian_noise\n",
    "    ]\n",
    "    augmentation = random.choice(augmentations)\n",
    "    return augmentation(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_dropped_patches = 0\n",
    "\n",
    "\n",
    "\n",
    "def reduce_resolution(image, target_size=(16, 16)):\n",
    "    \"\"\"Reduce and then restore the resolution of an image.\"\"\"\n",
    "    low_res = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    restored = cv2.resize(low_res, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    return restored\n",
    "\n",
    "def extract_patches(image, patch_size=1):\n",
    "    \"\"\"\n",
    "    Extract patches from an image.\n",
    "    Returns a list of flattened patch intensities.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    patches = []\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size].flatten()\n",
    "            patches.append(np.mean(patch))  # Use mean intensity as a feature\n",
    "    return patches\n",
    "\n",
    "def compute_global_correlation(data_dir, categories, patch_size=1):\n",
    "    \"\"\"\n",
    "    Compute the correlation of patches across the entire dataset with the label.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for img_name in tqdm(os.listdir(category_path)):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    # print(\"image shape\", image.shape)\n",
    "                    features = extract_patches(image, patch_size)\n",
    "                    # print(\"total patches:\", len(features))\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "    # print(len(all_features))\n",
    "    all_features = StandardScaler().fit_transform(all_features)\n",
    "    # Convert to a DataFrame for correlation calculation\n",
    "    feature_matrix = pd.DataFrame(all_features)  # Rows = images, Columns = patches\n",
    "    print(\"Feature_Matrix.Head()..........\")\n",
    "    print(feature_matrix.head())\n",
    "    label_series = pd.Series(all_labels, name=\"label\")\n",
    "    # print(label_series)\n",
    "    correlations = feature_matrix.corrwith(label_series)  # Correlation of each patch with the label\n",
    "    print(\"Correlation.Head()...........\")\n",
    "    print(correlations.head())\n",
    "    print(f\"Max correlation: {abs(correlations.max())}\")\n",
    "    print(f\"Min correlation: {abs(correlations.min())}\")\n",
    "    print(f\"Max correlation index: {abs(correlations).idxmax()}\")\n",
    "    print(f\"Size of correlation: {correlations.size}\")\n",
    "\n",
    "    return correlations\n",
    "\n",
    "def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Drop patches with the least correlation to the label.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    dropped_image = image.copy()\n",
    "    patch_idx = 0\n",
    "\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "                dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "                # n_dropped_patches += 1\n",
    "            patch_idx += 1\n",
    "\n",
    "    return dropped_image\n",
    "\n",
    "def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Process the entire dataset by dropping least correlated patches and saving.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    for img_name in tqdm(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                processed_image = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "                output_img_path = os.path.join(output_dir, img_name)\n",
    "                cv2.imwrite(output_img_path, processed_image)\n",
    "                    \n",
    "\n",
    "\n",
    "# def normalize_image(image):\n",
    "#     \"\"\"Normalize image to range [0, 1].\"\"\"\n",
    "#     return image / 255.0\n",
    "    \n",
    "def process_and_save_images(input_path, output_path, preprocess_fn, augment = True):\n",
    "    \"\"\"Process images with a given preprocessing function and save.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    image_paths = os.listdir(input_path)\n",
    "    for img_name in tqdm(image_paths):\n",
    "        img_path = os.path.join(input_path, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            processed_image = preprocess_fn(image)\n",
    "            if augment:\n",
    "                img_name = img_name.split('.')[0] + '_1.' + img_name.split('.')[1]\n",
    "            output_img_path = os.path.join(output_path, img_name)\n",
    "            cv2.imwrite(output_img_path, (processed_image * 255).astype(np.uint8) if processed_image.max() <= 1 else processed_image)\n",
    "\n",
    "\n",
    "base_dir = \"/kaggle/working/data\"  # Replace with the root path of your dataset\n",
    "subsets = [ \"train\",\"val\"]\n",
    "categories = {\"REAL\": 1, \"FAKE\": 0}\n",
    "train_data_dir = \"/kaggle/working/data/train\"  # Training data directory\n",
    "\n",
    "test_real_path = \"/kaggle/working/data/test/REAL\"\n",
    "test_fake_path = \"/kaggle/working/data/test/FAKE\"\n",
    "\n",
    "print(f\"Processing test/REAL...\")\n",
    "process_and_save_images(test_real_path, test_real_path, lambda img: add_gaussian_noise(img))\n",
    "print(f\"Processing test/FAKE...\")\n",
    "process_and_save_images(test_fake_path, test_fake_path, lambda img: add_gaussian_noise(img))\n",
    "\n",
    "# Apply the Robustness Methods to train and val set\n",
    "for subset in subsets:\n",
    "    for category, label in categories.items():\n",
    "        input_path = os.path.join(base_dir, subset, category)\n",
    "        # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "        print(f\"Processing {subset}/{category} for random augmentation...\")\n",
    "        process_and_save_images(input_path, input_path, lambda img: augment_image_randomly(img))\n",
    "\n",
    "\n",
    "print(\"Computing global correlation...\")\n",
    "correlations = compute_global_correlation(train_data_dir, categories, patch_size=1)\n",
    "\n",
    "all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# drop least correlated features from all sets \n",
    "for subset in all_subsets:\n",
    "    for category, label in categories.items():\n",
    "        # n_dropped_patches = 0\n",
    "        input_path = os.path.join(base_dir, subset, category)        \n",
    "        print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "        process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.015)\n",
    "\n",
    "# Apply the Robustness Methods to train and val set\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         # print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         # process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))\n",
    "        \n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for normalization...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: normalize_image(img), augment = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea032baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:19.887350Z",
     "iopub.status.busy": "2024-12-16T21:02:19.886158Z",
     "iopub.status.idle": "2024-12-16T21:02:19.891700Z",
     "shell.execute_reply": "2024-12-16T21:02:19.890874Z"
    },
    "papermill": {
     "duration": 0.697397,
     "end_time": "2024-12-16T21:02:19.893237",
     "exception": false,
     "start_time": "2024-12-16T21:02:19.195840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree('/kaggle/working/kaggle')\n",
    "# shutil.copytree('/kaggle/input/cifake-data-processed/data', '/kaggle/working/data_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53c6d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:21.356360Z",
     "iopub.status.busy": "2024-12-16T21:02:21.356028Z",
     "iopub.status.idle": "2024-12-16T21:02:21.360473Z",
     "shell.execute_reply": "2024-12-16T21:02:21.359378Z"
    },
    "papermill": {
     "duration": 0.738901,
     "end_time": "2024-12-16T21:02:21.362109",
     "exception": false,
     "start_time": "2024-12-16T21:02:20.623208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original_data_dir = \"/kaggle/working/data_original\"\n",
    "# data_dir = \"/kaggle/working/data\"\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(original_data_dir, subset, category)\n",
    "#         output_path = os.path.join(data_dir, subset, category)\n",
    "#         if not os.path.exists(output_path):\n",
    "#             os.makedirs(output_path)\n",
    "#         image_paths = os.listdir(input_path)\n",
    "#         if len(image_paths) > 0.1 * len(image_paths):\n",
    "#             image_paths = image_paths[int(0.1 * len(image_paths)):]\n",
    "#             for img_name in image_paths:\n",
    "#                 img_path = os.path.join(input_path, img_name)\n",
    "#                 shutil.copy(img_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a857cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:22.760256Z",
     "iopub.status.busy": "2024-12-16T21:02:22.759891Z",
     "iopub.status.idle": "2024-12-16T21:02:22.763889Z",
     "shell.execute_reply": "2024-12-16T21:02:22.763223Z"
    },
    "papermill": {
     "duration": 0.725315,
     "end_time": "2024-12-16T21:02:22.765418",
     "exception": false,
     "start_time": "2024-12-16T21:02:22.040103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Drop 80% of the images in the training set\n",
    "# all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         image_paths = os.listdir(input_path)\n",
    "#         if len(image_paths) > 0.2 * len(image_paths):\n",
    "#             image_paths = image_paths[:int(0.8 * len(image_paths))]\n",
    "#             for img_name in image_paths:\n",
    "#                 img_path = os.path.join(input_path, img_name)\n",
    "#                 os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e404e1d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:24.219822Z",
     "iopub.status.busy": "2024-12-16T21:02:24.219479Z",
     "iopub.status.idle": "2024-12-16T21:02:24.223441Z",
     "shell.execute_reply": "2024-12-16T21:02:24.222643Z"
    },
    "papermill": {
     "duration": 0.731106,
     "end_time": "2024-12-16T21:02:24.225076",
     "exception": false,
     "start_time": "2024-12-16T21:02:23.493970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Apply the Robustness Methods to train and val set\n",
    "# for subset in subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for random augmentation...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: augment_image_randomly(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf47d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:25.634732Z",
     "iopub.status.busy": "2024-12-16T21:02:25.634312Z",
     "iopub.status.idle": "2024-12-16T21:02:25.638720Z",
     "shell.execute_reply": "2024-12-16T21:02:25.637996Z"
    },
    "papermill": {
     "duration": 0.738612,
     "end_time": "2024-12-16T21:02:25.640389",
     "exception": false,
     "start_time": "2024-12-16T21:02:24.901777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_dropped_patches = 0\n",
    "# def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Drop patches with the least correlation to the label.\n",
    "#     \"\"\"\n",
    "#     height, width, _ = image.shape\n",
    "#     dropped_image = image.copy()\n",
    "#     patch_idx = 0\n",
    "#     n_dropped_patches = 0\n",
    "#     for i in range(0, height, patch_size):\n",
    "#         for j in range(0, width, patch_size):\n",
    "#             if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "#                 dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "#                 n_dropped_patches += 1\n",
    "#             patch_idx += 1\n",
    "#     print(f\"Dropped {n_dropped_patches} patches in this image\")\n",
    "#     return dropped_image, n_dropped_patches\n",
    "# def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Process the entire dataset by dropping least correlated patches and saving.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     n_dropped_patches = 0\n",
    "#     for img_name in tqdm(os.listdir(data_dir)):\n",
    "#         img_path = os.path.join(data_dir, img_name)\n",
    "#         if os.path.isfile(img_path):\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 processed_image, n_d = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "#                 n_dropped_patches += n_d\n",
    "#                 output_img_path = os.path.join(output_dir, img_name)\n",
    "#                 cv2.imwrite(output_img_path, processed_image)\n",
    "#     return n_dropped_patches \n",
    "                \n",
    "# all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# # drop least correlated features from all sets \n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         n_dropped_patches = 0\n",
    "#         input_path = os.path.join(base_dir, subset, category)   \n",
    "#         output_path = os.path.join(base_dir, subset, category+\"_processed\")\n",
    "#         print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "#         n_dropped_patches = process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.02)\n",
    "#         print(f\"Dropped {n_dropped_patches} patches in total in images of {subset}/{category}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d7f6874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:27.067346Z",
     "iopub.status.busy": "2024-12-16T21:02:27.067015Z",
     "iopub.status.idle": "2024-12-16T21:02:27.070788Z",
     "shell.execute_reply": "2024-12-16T21:02:27.069961Z"
    },
    "papermill": {
     "duration": 0.752766,
     "end_time": "2024-12-16T21:02:27.072383",
     "exception": false,
     "start_time": "2024-12-16T21:02:26.319617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r '/kaggle/working/data/train.cache'\n",
    "# !rm -r '/kaggle/working/data/val.cache'\n",
    "# !rm -r '/kaggle/working/data/test.cache'\n",
    "# !rm -r '/kaggle/working/runs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2803869b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:28.555167Z",
     "iopub.status.busy": "2024-12-16T21:02:28.554371Z",
     "iopub.status.idle": "2024-12-16T21:02:28.558323Z",
     "shell.execute_reply": "2024-12-16T21:02:28.557609Z"
    },
    "papermill": {
     "duration": 0.743098,
     "end_time": "2024-12-16T21:02:28.559871",
     "exception": false,
     "start_time": "2024-12-16T21:02:27.816773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for subset in subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2af2aad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:30.105122Z",
     "iopub.status.busy": "2024-12-16T21:02:30.104764Z",
     "iopub.status.idle": "2024-12-16T21:02:30.517072Z",
     "shell.execute_reply": "2024-12-16T21:02:30.516191Z"
    },
    "papermill": {
     "duration": 1.14919,
     "end_time": "2024-12-16T21:02:30.518843",
     "exception": false,
     "start_time": "2024-12-16T21:02:29.369653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REAL': 100000, 'FAKE': 120000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import cls_img_counter\n",
    "\n",
    "cls_img_counter('/kaggle/working/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3837fae",
   "metadata": {
    "papermill": {
     "duration": 0.729668,
     "end_time": "2024-12-16T21:02:31.925983",
     "exception": false,
     "start_time": "2024-12-16T21:02:31.196315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b632a32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:02:33.402250Z",
     "iopub.status.busy": "2024-12-16T21:02:33.401876Z",
     "iopub.status.idle": "2024-12-16T21:50:34.189370Z",
     "shell.execute_reply": "2024-12-16T21:50:34.188284Z"
    },
    "papermill": {
     "duration": 2881.526974,
     "end_time": "2024-12-16T21:50:34.191750",
     "exception": false,
     "start_time": "2024-12-16T21:02:32.664776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt to 'yolo11x-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56.9M/56.9M [00:00<00:00, 196MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/kaggle/working/data, epochs=5, time=None, patience=100, batch=16, imgsz=32, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:02:41,376\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-16 21:02:41,825\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLO11x-cls summary: 309 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 71.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/train... 132000 images, 0 corrupt: 100%|██████████| 132000/132000 [00:59<00:00, 2213.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/val... 44000 images, 0 corrupt: 100%|██████████| 44000/44000 [00:19<00:00, 2216.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 32 train, 32 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.682G     0.8703         16         32:   0%|          | 4/8250 [00:00<24:09,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.682G     0.8986         16         32:   0%|          | 10/8250 [00:01<13:41, 10.03it/s]\n",
      "100%|██████████| 755k/755k [00:00<00:00, 19.2MB/s]\n",
      "        1/5     0.694G     0.6222         16         32: 100%|██████████| 8250/8250 [09:39<00:00, 14.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:27<00:00, 49.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.812          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5     0.692G      0.633         16         32: 100%|██████████| 8250/8250 [08:47<00:00, 15.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:27<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5     0.705G     0.5896         16         32: 100%|██████████| 8250/8250 [08:26<00:00, 16.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:28<00:00, 48.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.845          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5     0.709G     0.5158         16         32: 100%|██████████| 8250/8250 [08:16<00:00, 16.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:27<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.834          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5     0.703G     0.4313         16         32: 100%|██████████| 8250/8250 [08:20<00:00, 16.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:27<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.863          1\n",
      "\n",
      "5 epochs completed in 0.767 hours.\n",
      "Optimizer stripped from runs/classify/train/weights/last.pt, 57.0MB\n",
      "Optimizer stripped from runs/classify/train/weights/best.pt, 57.0MB\n",
      "\n",
      "Validating runs/classify/train/weights/best.pt...\n",
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 1375/1375 [00:19<00:00, 69.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.863          1\n",
      "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model='yolo11x-cls.pt')\n",
    "results = model.train(data='/kaggle/working/data', epochs=5, imgsz=32, verbose= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6d1eca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:50:41.861497Z",
     "iopub.status.busy": "2024-12-16T21:50:41.860896Z",
     "iopub.status.idle": "2024-12-16T21:51:40.321762Z",
     "shell.execute_reply": "2024-12-16T21:51:40.320997Z"
    },
    "papermill": {
     "duration": 62.274197,
     "end_time": "2024-12-16T21:51:40.323712",
     "exception": false,
     "start_time": "2024-12-16T21:50:38.049515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 132000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 44000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/test... 44000 images, 0 corrupt: 100%|██████████| 44000/44000 [00:20<00:00, 2186.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /kaggle/working/data/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 2750/2750 [00:33<00:00, 81.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.847          1\n",
      "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "test_results = model.val(data='/kaggle/working/data', imgsz=32, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3d838a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T21:51:48.113964Z",
     "iopub.status.busy": "2024-12-16T21:51:48.113586Z",
     "iopub.status.idle": "2024-12-16T21:51:53.362201Z",
     "shell.execute_reply": "2024-12-16T21:51:53.361436Z"
    },
    "papermill": {
     "duration": 9.197908,
     "end_time": "2024-12-16T21:51:53.364223",
     "exception": false,
     "start_time": "2024-12-16T21:51:44.166315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "model.save('trained_yolo_model.pt')\n",
    "shutil.rmtree('/kaggle/working/data')\n",
    "# shutil.rmtree('/kaggle/working/raw')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6314726,
     "sourceId": 10216094,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5289.723403,
   "end_time": "2024-12-16T21:52:00.128967",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T20:23:50.405564",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
