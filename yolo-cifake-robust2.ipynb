{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dfc81d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T09:23:35.005568Z",
     "iopub.status.busy": "2024-12-16T09:23:35.004999Z",
     "iopub.status.idle": "2024-12-16T09:23:46.912176Z",
     "shell.execute_reply": "2024-12-16T09:23:46.911368Z"
    },
    "papermill": {
     "duration": 11.914838,
     "end_time": "2024-12-16T09:23:46.914075",
     "exception": false,
     "start_time": "2024-12-16T09:23:34.999237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1b7b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:23:46.924709Z",
     "iopub.status.busy": "2024-12-16T09:23:46.923883Z",
     "iopub.status.idle": "2024-12-16T09:23:56.611068Z",
     "shell.execute_reply": "2024-12-16T09:23:56.609924Z"
    },
    "papermill": {
     "duration": 9.694512,
     "end_time": "2024-12-16T09:23:56.613295",
     "exception": false,
     "start_time": "2024-12-16T09:23:46.918783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wolta\r\n",
      "  Downloading wolta-0.3.5-py3-none-any.whl.metadata (960 bytes)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.2)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from wolta) (2.2.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from wolta) (1.26.4)\r\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.10/site-packages (from wolta) (0.2.7)\r\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (from wolta) (1.2.7)\r\n",
      "Collecting imblearn (from wolta)\r\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\r\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from wolta) (4.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wolta) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from wolta) (4.10.0.84)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (0.20.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.14.1)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost->wolta) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->wolta) (2024.1)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (4.66.4)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (3.0.0)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt->wolta) (0.10.9.7)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from imblearn->wolta) (0.12.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wolta) (3.1.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->wolta) (3.5.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost->wolta) (8.3.0)\r\n",
      "Downloading wolta-0.3.5-py3-none-any.whl (17 kB)\r\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Installing collected packages: imblearn, wolta\r\n",
      "Successfully installed imblearn-0.0 wolta-0.3.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wolta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da728e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:23:56.625566Z",
     "iopub.status.busy": "2024-12-16T09:23:56.625252Z",
     "iopub.status.idle": "2024-12-16T09:24:05.620907Z",
     "shell.execute_reply": "2024-12-16T09:24:05.620025Z"
    },
    "papermill": {
     "duration": 9.004734,
     "end_time": "2024-12-16T09:24:05.623042",
     "exception": false,
     "start_time": "2024-12-16T09:23:56.618308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.49 ultralytics-thop-2.0.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b1da75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:24:05.635690Z",
     "iopub.status.busy": "2024-12-16T09:24:05.635384Z",
     "iopub.status.idle": "2024-12-16T09:24:05.639767Z",
     "shell.execute_reply": "2024-12-16T09:24:05.639025Z"
    },
    "papermill": {
     "duration": 0.012461,
     "end_time": "2024-12-16T09:24:05.641235",
     "exception": false,
     "start_time": "2024-12-16T09:24:05.628774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0391f",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2024-12-16T09:24:05.651404",
     "exception": false,
     "start_time": "2024-12-16T09:24:05.646433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916ca216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:24:05.662735Z",
     "iopub.status.busy": "2024-12-16T09:24:05.662485Z",
     "iopub.status.idle": "2024-12-16T09:26:38.660033Z",
     "shell.execute_reply": "2024-12-16T09:26:38.659171Z"
    },
    "papermill": {
     "duration": 153.01001,
     "end_time": "2024-12-16T09:26:38.666508",
     "exception": false,
     "start_time": "2024-12-16T09:24:05.656498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/test\n",
      "/kaggle/input/test/FAKE\n",
      "/kaggle/input/test/REAL\n",
      "/kaggle/input/train\n",
      "/kaggle/input/train/FAKE\n",
      "/kaggle/input/train/REAL\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, _ in os.walk('/kaggle/input'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5bebf87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:26:38.678443Z",
     "iopub.status.busy": "2024-12-16T09:26:38.678174Z",
     "iopub.status.idle": "2024-12-16T09:26:38.684431Z",
     "shell.execute_reply": "2024-12-16T09:26:38.683706Z"
    },
    "papermill": {
     "duration": 0.01395,
     "end_time": "2024-12-16T09:26:38.685951",
     "exception": false,
     "start_time": "2024-12-16T09:26:38.672001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/test/FAKE', '/kaggle/input/test/REAL', '/kaggle/input/train/FAKE', '/kaggle/input/train/REAL']\n"
     ]
    }
   ],
   "source": [
    "p_paths = glob('/kaggle/input/*')\n",
    "d_paths = []\n",
    "\n",
    "for p_path in p_paths:\n",
    "    d_paths.extend(glob('{}/*'.format(p_path)))\n",
    "print(d_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9fb7cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:26:38.697878Z",
     "iopub.status.busy": "2024-12-16T09:26:38.697619Z",
     "iopub.status.idle": "2024-12-16T09:26:39.019004Z",
     "shell.execute_reply": "2024-12-16T09:26:39.018119Z"
    },
    "papermill": {
     "duration": 0.329154,
     "end_time": "2024-12-16T09:26:39.020641",
     "exception": false,
     "start_time": "2024-12-16T09:26:38.691487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    }
   ],
   "source": [
    "i_paths = []\n",
    "\n",
    "for d_path in d_paths:\n",
    "    i_paths.extend(glob('{}/*'.format(d_path)))\n",
    "\n",
    "print(len(i_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dac6e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:26:39.033173Z",
     "iopub.status.busy": "2024-12-16T09:26:39.032925Z",
     "iopub.status.idle": "2024-12-16T09:26:39.550041Z",
     "shell.execute_reply": "2024-12-16T09:26:39.549306Z"
    },
    "papermill": {
     "duration": 0.525172,
     "end_time": "2024-12-16T09:26:39.551874",
     "exception": false,
     "start_time": "2024-12-16T09:26:39.026702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 120000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import get_extensions\n",
    "\n",
    "get_extensions(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37641be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:26:39.564807Z",
     "iopub.status.busy": "2024-12-16T09:26:39.564559Z",
     "iopub.status.idle": "2024-12-16T09:36:21.662784Z",
     "shell.execute_reply": "2024-12-16T09:36:21.661851Z"
    },
    "papermill": {
     "duration": 582.111675,
     "end_time": "2024-12-16T09:36:21.669687",
     "exception": false,
     "start_time": "2024-12-16T09:26:39.558012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import dataset_size_same\n",
    "\n",
    "dataset_size_same(i_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8fd853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:36:21.683437Z",
     "iopub.status.busy": "2024-12-16T09:36:21.683121Z",
     "iopub.status.idle": "2024-12-16T09:36:21.690291Z",
     "shell.execute_reply": "2024-12-16T09:36:21.689334Z"
    },
    "papermill": {
     "duration": 0.016349,
     "end_time": "2024-12-16T09:36:21.691878",
     "exception": false,
     "start_time": "2024-12-16T09:36:21.675529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 32\n",
      "Height: 32\n",
      "Ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "temp_img = cv2.imread(i_paths[0])\n",
    "ratio = temp_img.shape[1] / temp_img.shape[0]\n",
    "\n",
    "print('Width: {}'.format(temp_img.shape[1]))\n",
    "print('Height: {}'.format(temp_img.shape[0]))\n",
    "print('Ratio: {}'.format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af328d",
   "metadata": {
    "papermill": {
     "duration": 0.005677,
     "end_time": "2024-12-16T09:36:21.703312",
     "exception": false,
     "start_time": "2024-12-16T09:36:21.697635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3663d0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:36:21.715940Z",
     "iopub.status.busy": "2024-12-16T09:36:21.715679Z",
     "iopub.status.idle": "2024-12-16T09:36:21.719523Z",
     "shell.execute_reply": "2024-12-16T09:36:21.718857Z"
    },
    "papermill": {
     "duration": 0.011758,
     "end_time": "2024-12-16T09:36:21.720933",
     "exception": false,
     "start_time": "2024-12-16T09:36:21.709175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d892d4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:36:21.733109Z",
     "iopub.status.busy": "2024-12-16T09:36:21.732864Z",
     "iopub.status.idle": "2024-12-16T09:41:01.274646Z",
     "shell.execute_reply": "2024-12-16T09:41:01.273895Z"
    },
    "papermill": {
     "duration": 279.550267,
     "end_time": "2024-12-16T09:41:01.276845",
     "exception": false,
     "start_time": "2024-12-16T09:36:21.726578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d_path in d_paths:\n",
    "    current_dir = Path(d_path).name\n",
    "    current_path = '/kaggle/working/raw/{}'.format(current_dir) \n",
    "    os.makedirs(current_path, exist_ok=True)\n",
    "\n",
    "    i_paths = glob('{}/*'.format(d_path))\n",
    "\n",
    "    for i_path in i_paths:\n",
    "        shutil.copy(i_path, current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2095264",
   "metadata": {
    "papermill": {
     "duration": 0.00593,
     "end_time": "2024-12-16T09:41:01.288993",
     "exception": false,
     "start_time": "2024-12-16T09:41:01.283063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c7e3687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:41:01.301443Z",
     "iopub.status.busy": "2024-12-16T09:41:01.301208Z",
     "iopub.status.idle": "2024-12-16T09:41:12.129422Z",
     "shell.execute_reply": "2024-12-16T09:41:12.128705Z"
    },
    "papermill": {
     "duration": 10.836568,
     "end_time": "2024-12-16T09:41:12.131296",
     "exception": false,
     "start_time": "2024-12-16T09:41:01.294728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wolta.visual_tools import dir_split\n",
    "\n",
    "dir_split('/kaggle/working/raw', '/kaggle/working/data', test_size=0.2, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccd2c0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:41:12.144801Z",
     "iopub.status.busy": "2024-12-16T09:41:12.144279Z",
     "iopub.status.idle": "2024-12-16T09:56:21.696233Z",
     "shell.execute_reply": "2024-12-16T09:56:21.695276Z"
    },
    "papermill": {
     "duration": 909.561059,
     "end_time": "2024-12-16T09:56:21.698480",
     "exception": false,
     "start_time": "2024-12-16T09:41:12.137421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/REAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3926.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test/FAKE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:03<00:00, 3668.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing global correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [03:42<00:00, 134.86it/s]\n",
      "100%|██████████| 36000/36000 [04:29<00:00, 133.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_Matrix.Head()..........\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0  1.670720  1.723971  1.756896  1.789645  1.795553  1.793491  1.793380   \n",
      "1 -1.607292 -1.635518 -1.664833 -1.688951 -1.716889 -1.735320 -1.759316   \n",
      "2 -1.384008 -1.370801 -1.355087 -1.285142 -1.159203 -1.048208 -1.068514   \n",
      "3 -0.144064 -0.032781 -0.125781 -0.020198 -0.029156 -0.670297 -1.063580   \n",
      "4  0.725322  0.693985  0.726021  0.816611  0.792697  0.463438 -0.091522   \n",
      "\n",
      "       7         8         9     ...      1014      1015      1016      1017  \\\n",
      "0  1.812419  1.745124  1.818243  ... -1.035983  0.445862  0.482222  0.630716   \n",
      "1 -1.771534 -1.743997 -1.723440  ... -0.976827 -0.805934 -0.568173 -1.105014   \n",
      "2 -1.173385 -1.079874 -1.037953  ...  1.140954  1.142617  1.160849  1.120735   \n",
      "3 -0.688933 -0.058910 -0.163708  ...  0.685454 -0.652412 -0.751107 -0.981033   \n",
      "4 -0.545575 -0.648690 -0.566059  ...  0.851090  0.699764  0.635651  0.447697   \n",
      "\n",
      "       1018      1019      1020      1021      1022      1023  \n",
      "0  0.656309  0.507115  0.504836  0.618584  0.570530  0.380760  \n",
      "1 -0.772631 -0.828376 -0.691100 -0.705748 -0.636337 -0.757791  \n",
      "2  1.091460  1.083670  1.026593  0.951126  0.889653  0.867075  \n",
      "3 -0.884359 -0.834259 -0.949047 -0.676578 -0.270796 -0.277197  \n",
      "4  0.279963 -0.004725 -0.661788 -1.394168 -1.634323 -1.455797  \n",
      "\n",
      "[5 rows x 1024 columns]\n",
      "Correlation.Head()...........\n",
      "0    0.261118\n",
      "1    0.250484\n",
      "2    0.244802\n",
      "3    0.236120\n",
      "4    0.229740\n",
      "dtype: float64\n",
      "Max correlation: 0.2644617291379184\n",
      "Min correlation: 0.0005441640635258495\n",
      "Max correlation index: 992\n",
      "Size of correlation: 1024\n",
      "Processing train/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [01:30<00:00, 330.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of train/REAL.\n",
      "Processing train/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36000/36000 [01:49<00:00, 329.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of train/FAKE.\n",
      "Processing val/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:30<00:00, 329.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of val/REAL.\n",
      "Processing val/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:36<00:00, 329.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of val/FAKE.\n",
      "Processing test/REAL for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:00<00:00, 328.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of test/REAL.\n",
      "Processing test/FAKE for feature dropping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [01:13<00:00, 328.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 patches in total in images of test/FAKE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_dropped_patches = 0\n",
    "def add_gaussian_noise(image, mean=0, std=25):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def reduce_resolution(image, target_size=(16, 16)):\n",
    "    \"\"\"Reduce and then restore the resolution of an image.\"\"\"\n",
    "    low_res = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    restored = cv2.resize(low_res, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    return restored\n",
    "\n",
    "def extract_patches(image, patch_size=1):\n",
    "    \"\"\"\n",
    "    Extract patches from an image.\n",
    "    Returns a list of flattened patch intensities.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    patches = []\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size].flatten()\n",
    "            patches.append(np.mean(patch))  # Use mean intensity as a feature\n",
    "    return patches\n",
    "\n",
    "def compute_global_correlation(data_dir, categories, patch_size=1):\n",
    "    \"\"\"\n",
    "    Compute the correlation of patches across the entire dataset with the label.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for img_name in tqdm(os.listdir(category_path)):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    features = extract_patches(image, patch_size)\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "    all_features = StandardScaler().fit_transform(all_features)\n",
    "    # Convert to a DataFrame for correlation calculation\n",
    "    feature_matrix = pd.DataFrame(all_features)  # Rows = images, Columns = patches\n",
    "    print(\"Feature_Matrix.Head()..........\")\n",
    "    print(feature_matrix.head())\n",
    "    label_series = pd.Series(all_labels, name=\"label\")\n",
    "    # print(label_series)\n",
    "    correlations = feature_matrix.corrwith(label_series)  # Correlation of each patch with the label\n",
    "    print(\"Correlation.Head()...........\")\n",
    "    print(correlations.head())\n",
    "    print(f\"Max correlation: {abs(correlations.max())}\")\n",
    "    print(f\"Min correlation: {abs(correlations.min())}\")\n",
    "    print(f\"Max correlation index: {abs(correlations).idxmax()}\")\n",
    "    print(f\"Size of correlation: {correlations.size}\")\n",
    "\n",
    "    return correlations\n",
    "\n",
    "def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Drop patches with the least correlation to the label.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    dropped_image = image.copy()\n",
    "    patch_idx = 0\n",
    "\n",
    "    for i in range(0, height, patch_size):\n",
    "        for j in range(0, width, patch_size):\n",
    "            if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "                dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "                # n_dropped_patches += 1\n",
    "            patch_idx += 1\n",
    "\n",
    "    return dropped_image\n",
    "\n",
    "def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Process the entire dataset by dropping least correlated patches and saving.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "    for img_name in tqdm(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                processed_image = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "                output_img_path = os.path.join(output_dir, img_name)\n",
    "                cv2.imwrite(output_img_path, processed_image)\n",
    "                    \n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image to range [0, 1].\"\"\"\n",
    "    return image / 255.0\n",
    "    \n",
    "def process_and_save_images(input_path, output_path, preprocess_fn, augment = True):\n",
    "    \"\"\"Process images with a given preprocessing function and save.\"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    image_paths = os.listdir(input_path)\n",
    "    for img_name in tqdm(image_paths):\n",
    "        img_path = os.path.join(input_path, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            processed_image = preprocess_fn(image)\n",
    "            if augment:\n",
    "                img_name = img_name.split('.')[0] + '_1.' + img_name.split('.')[1]\n",
    "            output_img_path = os.path.join(output_path, img_name)\n",
    "            cv2.imwrite(output_img_path, (processed_image * 255).astype(np.uint8) if processed_image.max() <= 1 else processed_image)\n",
    "\n",
    "\n",
    "base_dir = \"/kaggle/working/data\"  # Replace with the root path of your dataset\n",
    "subsets = [ \"train\",\"val\"]\n",
    "categories = {\"REAL\": 1, \"FAKE\": 0}\n",
    "train_data_dir = \"/kaggle/working/data/train\"  # Training data directory\n",
    "\n",
    "test_real_path = \"/kaggle/working/data/test/REAL\"\n",
    "test_fake_path = \"/kaggle/working/data/test/FAKE\"\n",
    "\n",
    "print(f\"Processing test/REAL...\")\n",
    "process_and_save_images(test_real_path, test_real_path, lambda img: add_gaussian_noise(img))\n",
    "print(f\"Processing test/FAKE...\")\n",
    "process_and_save_images(test_fake_path, test_fake_path, lambda img: add_gaussian_noise(img))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Computing global correlation...\")\n",
    "correlations = compute_global_correlation(train_data_dir, categories, patch_size=1)\n",
    "\n",
    "all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# drop least correlated features from all sets \n",
    "for subset in all_subsets:\n",
    "    for category, label in categories.items():\n",
    "        # n_dropped_patches = 0\n",
    "        input_path = os.path.join(base_dir, subset, category)        \n",
    "        print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "        process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.02)\n",
    "        print(f\"Dropped {n_dropped_patches} patches in total in images of {subset}/{category}.\")\n",
    "\n",
    "# Apply the Robustness Methods to train and val set\n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         # print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         # process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))\n",
    "        \n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for normalization...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: normalize_image(img), augment = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32002fc8",
   "metadata": {
    "papermill": {
     "duration": 0.419365,
     "end_time": "2024-12-16T09:56:22.496053",
     "exception": false,
     "start_time": "2024-12-16T09:56:22.076688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1df106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:23.263791Z",
     "iopub.status.busy": "2024-12-16T09:56:23.262934Z",
     "iopub.status.idle": "2024-12-16T09:56:23.268979Z",
     "shell.execute_reply": "2024-12-16T09:56:23.268191Z"
    },
    "papermill": {
     "duration": 0.391042,
     "end_time": "2024-12-16T09:56:23.270641",
     "exception": false,
     "start_time": "2024-12-16T09:56:22.879599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_dropped_patches = 0\n",
    "# def drop_least_correlated_features(image, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Drop patches with the least correlation to the label.\n",
    "#     \"\"\"\n",
    "#     height, width, _ = image.shape\n",
    "#     dropped_image = image.copy()\n",
    "#     patch_idx = 0\n",
    "#     n_dropped_patches = 0\n",
    "#     for i in range(0, height, patch_size):\n",
    "#         for j in range(0, width, patch_size):\n",
    "#             if patch_idx < len(correlations) and abs(correlations[patch_idx]) < threshold:\n",
    "#                 dropped_image[i:i+patch_size, j:j+patch_size] = 0  # Drop patch (set to black)\n",
    "#                 n_dropped_patches += 1\n",
    "#             patch_idx += 1\n",
    "#     print(f\"Dropped {n_dropped_patches} patches in this image\")\n",
    "#     return dropped_image, n_dropped_patches\n",
    "# def process_dataset_with_correlation(data_dir, output_dir, correlations, patch_size=1, threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Process the entire dataset by dropping least correlated patches and saving.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     n_dropped_patches = 0\n",
    "#     for img_name in tqdm(os.listdir(data_dir)):\n",
    "#         img_path = os.path.join(data_dir, img_name)\n",
    "#         if os.path.isfile(img_path):\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 processed_image, n_d = drop_least_correlated_features(image, correlations, patch_size, threshold)\n",
    "#                 n_dropped_patches += n_d\n",
    "#                 output_img_path = os.path.join(output_dir, img_name)\n",
    "#                 cv2.imwrite(output_img_path, processed_image)\n",
    "#     return n_dropped_patches \n",
    "                \n",
    "# all_subsets = [ \"train\",\"val\", \"test\"]\n",
    "\n",
    "# # drop least correlated features from all sets \n",
    "# for subset in all_subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         n_dropped_patches = 0\n",
    "#         input_path = os.path.join(base_dir, subset, category)   \n",
    "#         output_path = os.path.join(base_dir, subset, category+\"_processed\")\n",
    "#         print(f\"Processing {subset}/{category} for feature dropping...\")\n",
    "#         n_dropped_patches = process_dataset_with_correlation(input_path, input_path, correlations, patch_size=1, threshold=0.02)\n",
    "#         print(f\"Dropped {n_dropped_patches} patches in total in images of {subset}/{category}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a4c302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:24.053465Z",
     "iopub.status.busy": "2024-12-16T09:56:24.053061Z",
     "iopub.status.idle": "2024-12-16T09:56:24.057096Z",
     "shell.execute_reply": "2024-12-16T09:56:24.056440Z"
    },
    "papermill": {
     "duration": 0.376483,
     "end_time": "2024-12-16T09:56:24.058746",
     "exception": false,
     "start_time": "2024-12-16T09:56:23.682263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r '/kaggle/working/data/train.cache'\n",
    "# !rm -r '/kaggle/working/data/val.cache'\n",
    "# !rm -r '/kaggle/working/data/test.cache'\n",
    "# !rm -r '/kaggle/working/runs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc80118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:24.841770Z",
     "iopub.status.busy": "2024-12-16T09:56:24.840812Z",
     "iopub.status.idle": "2024-12-16T09:56:24.844722Z",
     "shell.execute_reply": "2024-12-16T09:56:24.844027Z"
    },
    "papermill": {
     "duration": 0.418494,
     "end_time": "2024-12-16T09:56:24.846357",
     "exception": false,
     "start_time": "2024-12-16T09:56:24.427863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.copytree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ad4800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:25.589716Z",
     "iopub.status.busy": "2024-12-16T09:56:25.589377Z",
     "iopub.status.idle": "2024-12-16T09:56:25.593253Z",
     "shell.execute_reply": "2024-12-16T09:56:25.592421Z"
    },
    "papermill": {
     "duration": 0.378996,
     "end_time": "2024-12-16T09:56:25.594836",
     "exception": false,
     "start_time": "2024-12-16T09:56:25.215840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for subset in subsets:\n",
    "#     for category, label in categories.items():\n",
    "#         input_path = os.path.join(base_dir, subset, category)\n",
    "#         # output_path = os.path.join(base_dir, f\"{subset}_{category}_processed\")\n",
    "        \n",
    "#         print(f\"Processing {subset}/{category} for reduced resolution...\")\n",
    "#         process_and_save_images(input_path, input_path, lambda img: reduce_resolution(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2a797e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:26.384062Z",
     "iopub.status.busy": "2024-12-16T09:56:26.383715Z",
     "iopub.status.idle": "2024-12-16T09:56:26.631991Z",
     "shell.execute_reply": "2024-12-16T09:56:26.631154Z"
    },
    "papermill": {
     "duration": 0.624448,
     "end_time": "2024-12-16T09:56:26.633739",
     "exception": false,
     "start_time": "2024-12-16T09:56:26.009291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REAL': 60000, 'FAKE': 72000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wolta.visual_tools import cls_img_counter\n",
    "\n",
    "cls_img_counter('/kaggle/working/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bd560",
   "metadata": {
    "papermill": {
     "duration": 0.38519,
     "end_time": "2024-12-16T09:56:27.436445",
     "exception": false,
     "start_time": "2024-12-16T09:56:27.051255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "556d7918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T09:56:28.231941Z",
     "iopub.status.busy": "2024-12-16T09:56:28.231634Z",
     "iopub.status.idle": "2024-12-16T10:21:00.697216Z",
     "shell.execute_reply": "2024-12-16T10:21:00.696369Z"
    },
    "papermill": {
     "duration": 1472.886319,
     "end_time": "2024-12-16T10:21:00.699334",
     "exception": false,
     "start_time": "2024-12-16T09:56:27.813015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-cls.pt to 'yolo11x-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56.9M/56.9M [00:00<00:00, 135MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/kaggle/working/data, epochs=5, time=None, patience=100, batch=16, imgsz=32, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 66000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 22000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 09:56:36,322\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-16 09:56:36,794\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLO11x-cls summary: 309 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 96.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/train... 66000 images, 0 corrupt: 100%|██████████| 66000/66000 [00:29<00:00, 2225.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/val... 22000 images, 0 corrupt: 100%|██████████| 22000/22000 [00:10<00:00, 2196.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 32 train, 32 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.803G      0.909         16         32:   0%|          | 5/4125 [00:01<10:58,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5     0.803G     0.9376         16         32:   0%|          | 11/4125 [00:01<06:27, 10.61it/s]\n",
      "100%|██████████| 755k/755k [00:00<00:00, 27.7MB/s]\n",
      "        1/5     0.816G     0.5488         16         32: 100%|██████████| 4125/4125 [04:59<00:00, 13.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:14<00:00, 49.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.891          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      0.81G     0.4055         16         32: 100%|██████████| 4125/4125 [04:27<00:00, 15.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:13<00:00, 49.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5     0.814G     0.3655         16         32: 100%|██████████| 4125/4125 [04:15<00:00, 16.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:13<00:00, 51.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      0.81G     0.3172         16         32: 100%|██████████| 4125/4125 [04:10<00:00, 16.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:14<00:00, 48.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5     0.805G     0.2777         16         32: 100%|██████████| 4125/4125 [04:10<00:00, 16.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:13<00:00, 49.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.390 hours.\n",
      "Optimizer stripped from runs/classify/train/weights/last.pt, 57.0MB\n",
      "Optimizer stripped from runs/classify/train/weights/best.pt, 57.0MB\n",
      "\n",
      "Validating runs/classify/train/weights/best.pt...\n",
      "Ultralytics 8.3.49 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 66000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 22000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 688/688 [00:10<00:00, 68.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94          1\n",
      "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model='yolo11x-cls.pt')\n",
    "results = model.train(data='/kaggle/working/data', epochs=5, imgsz=32, verbose= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa41786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:21:04.593573Z",
     "iopub.status.busy": "2024-12-16T10:21:04.593188Z",
     "iopub.status.idle": "2024-12-16T10:22:00.533737Z",
     "shell.execute_reply": "2024-12-16T10:22:00.532920Z"
    },
    "papermill": {
     "duration": 57.843111,
     "end_time": "2024-12-16T10:22:00.535659",
     "exception": false,
     "start_time": "2024-12-16T10:21:02.692548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 66000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 22000 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 44000 images in 2 classes ✅ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/test... 44000 images, 0 corrupt: 100%|██████████| 44000/44000 [00:19<00:00, 2201.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /kaggle/working/data/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 2750/2750 [00:32<00:00, 85.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.711          1\n",
      "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "test_results = model.val(data='/kaggle/working/data', imgsz=32, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8b0946f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T10:22:04.555929Z",
     "iopub.status.busy": "2024-12-16T10:22:04.555516Z",
     "iopub.status.idle": "2024-12-16T10:22:10.242389Z",
     "shell.execute_reply": "2024-12-16T10:22:10.241386Z"
    },
    "papermill": {
     "duration": 7.652397,
     "end_time": "2024-12-16T10:22:10.245421",
     "exception": false,
     "start_time": "2024-12-16T10:22:02.593024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('trained_yolo_model.pt')\n",
    "shutil.rmtree('/kaggle/working/data')\n",
    "shutil.rmtree('/kaggle/working/raw')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3041726,
     "sourceId": 5256696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3522.612409,
   "end_time": "2024-12-16T10:22:15.196710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T09:23:32.584301",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
